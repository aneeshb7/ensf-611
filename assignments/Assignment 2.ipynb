{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear Models and Validation Metrics (40 marks total)\n",
    "### Due: October 4 at 11:59pm\n",
    "\n",
    "### Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 1: Classification (20 marks)\n",
    "\n",
    "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c38f746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') #ignoring some deprication warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be imported using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
    "\n",
    "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x:  (4600, 57)\n",
      "Size of y:  (4600,)\n",
      "Type of x:  <class 'pandas.core.frame.DataFrame'>\n",
      "Type of y:  <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library (0.5 marks)\n",
    "from yellowbrick.datasets import load_spam\n",
    "\n",
    "# TO DO: Print the size of X and y (0.5 marks)\n",
    "X, y = load_spam()\n",
    "print(\"Size of x: \", X.shape)\n",
    "print(\"Size of y: \", y.shape)\n",
    "\n",
    "print(\"Type of x: \", type(X))\n",
    "print(\"Type of y: \", type(y))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (2 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7204f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary (1 mark)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489285a",
   "metadata": {},
   "source": [
    "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **4%** of the data. Use `random_state=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bc4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Create X_small and y_small (1 mark)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`\n",
    "3. Implement the machine learning model with three different datasets: \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model \n",
    "\n",
    "Calculate the training and validation accuracy for the three different tests implemented in Step 3. For this case, you can use `cross_validate()` with `cv=5` and `scoring='accuracy'` to get the training and validation data for each of the three datasets and calculate the accuracy results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {},
   "source": [
    "### Step 5.1: Visualize Results (3 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "2. Add the data size, training accuracy and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13a54f",
   "metadata": {},
   "source": [
    "### Step 5.2: Visualize Classification Errors (2 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6022252f",
   "metadata": {},
   "source": [
    "In this section, print the confusion matrix to investigate the number of false positives vs. false negatives. Use the full dataset for this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81931e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Retrieve target vector and predicted values for validation set using full dataset (1 mark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cb30f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Print confusion matrix using a heatmap (1 mark)\n",
    "# HINT: To remove scientific notation from a heatmap, set the parameter fmt='d'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {},
   "source": [
    "### Questions (8 marks)\n",
    "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
    "1. Why do the training and validation accuracy behave this way when the amount of data is changed? Relate your answer to concepts discussed in class.\n",
    "1. Do these results change based on the `random_state` selected for splitting the data into X_small and y_small? Why do you think it behaves this way?\n",
    "1. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
    "\n",
    "*ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE - BE SPECIFIC*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {},
   "source": [
    "## Part 2: Regression (18 marks)\n",
    "\n",
    "For this section, we will be using the auto-mpg dataset from Lab 2. You will need to repeat the steps from Part 1 for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (0.5 marks)\n",
    "\n",
    "The data used for this task can be downloaded from UCI website: https://archive.ics.uci.edu/ml/datasets/Auto%2BMPG \n",
    "\n",
    "Load the auto-mpg dataset and inspect the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Import auto-mpg data and inspect the first few rows (0.5 marks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (2.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc9c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary (1 mark)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04475f0a",
   "metadata": {},
   "source": [
    "Remove any columns that do not have numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fee994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Remove non-numeric data (0.5 marks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8df0b2a",
   "metadata": {},
   "source": [
    "Split the auto-mpg data into the feature matrix and target vector. Inspect the first few columns of the feature matrix to make sure it split properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Create feature matrix and target vector (1 mark) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "### Step 3: Implement and Validate Machine Learning Model (2.5 marks)\n",
    "\n",
    "1. Import any required libraries\n",
    "1. Split the data into training and testing sets (testing data should be 10% of the dataset)\n",
    "1. Instantiate model `LinearRegression()`\n",
    "1. Train and validate the machine learning model using the training set (using `cross_validate()` with `cv=5` and `scoring='r2'`)\n",
    "1. Print the training and validation accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4da0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Note: for any random state parameters, you can use random_state = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "### Step 4: Test Model (1 mark)\n",
    "\n",
    "Calculate the testing accuracy using the R^2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc93a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3f7a8",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (1.5 marks)\n",
    "\n",
    "1. Plot the relationship between each of the features and the target vector using `pairplot`\n",
    "1. Plot the correlation matrix\n",
    "1. Print the coefficients for each feature and the intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0546cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Plot pairplot (0.5 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773cfd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Plot correlation matrix (0.5 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ae0f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Print model coefficients and intercept (0.5 marks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. Did using a linear model produce good results for this dataset? Why or why not?\n",
    "1. Do the coefficients for each of the features make sense when compared to the `pairplot` and the correlation matrix? Why or why not?\n",
    "1. If you repeat this analysis with ridge regression, do the results change significantly? Why do you think is the cause of these (changed or unchanged) results?\n",
    "\n",
    "*ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE - BE SPECIFIC*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Part 3: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challenging, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867c484f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
