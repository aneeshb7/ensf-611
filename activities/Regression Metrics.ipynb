{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Metrics\n",
    "\n",
    "Follow _Introduction to Machine Learning_ [Chapter 5](https://github.com/amueller/introduction_to_ml_with_python/blob/master/05-model-evaluation-and-improvement.ipynb) **Section 5.3.4 Regression Metrics** (p.306)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression metrics\n",
    "\n",
    "R-squared `sklearn.metrics.r2_score`\n",
    ">It represents the proportion of variance (of y) that has been explained by the independent variables in the model. It provides an indication of goodness of fit and therefore a measure of how well unseen samples are likely to be predicted by the model, through the proportion of explained variance.\n",
    "\n",
    "see [Coefficient of determination](https://en.wikipedia.org/wiki/Coefficient_of_determination) for more information.\n",
    "\n",
    "$\\frac{\\sum(y - \\bar{y})^2 - \\sum(y - \\hat{y})^2}{\\sum(y - \\bar{y})^2} = 1 -  \\frac{\\sum(y - \\hat{y})^2}{\\sum(y - \\bar{y})^2}$\n",
    "\n",
    "Mean-squared error `sklearn.metrics.mean_squared_error`\n",
    "\n",
    "$\\frac{1}{N} \\sum (y - \\hat{y})^2$\n",
    "\n",
    "Root mean-squared error `sklearn.metrics.mean_squared_error(squared=False)`\n",
    "\n",
    "$\\sqrt{\\frac{1}{N} \\sum (y - \\hat{y})^2}$\n",
    "\n",
    "Mean absolute error `sklearn.metrics.mean_absolute_error`\n",
    "\n",
    "\n",
    "$\\frac{1}{N} \\sum |y - \\hat{y}|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 10*np.random.rand(50)+2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y + 2*np.random.rand(50)\n",
    "y_pred[-1] = 1.6 * y[-1] #a slight outlier\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted vs actual plot\n",
    "\n",
    "Combined with a line of unity to assess biases in predictons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_pred, y)\n",
    "plt.plot([0, 13], [0, 13])\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual plot\n",
    "\n",
    "Assess distribution of errors and dependency on magnitude of predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_pred, y-y_pred)\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual - predicted')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate R2 manually\n",
    "1 - sum((y-y_pred)**2)/sum((y-y.mean())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mse manually\n",
    "sum((y-y_pred)**2) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "mse(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rms manually\n",
    "np.sqrt(sum((y-y_pred)**2) / len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(y, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mae manually\n",
    "sum(np.abs(y-y_pred)) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "mae(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Negative $R^2$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10, 50)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(345)\n",
    "y = -0.1*x**2+np.random.randn(50)+8\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y, '.');\n",
    "plt.xlabel('feature')\n",
    "plt.ylabel('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(x[:,None],y).score(x[:,None],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xline = np.linspace(0, 10, 20)\n",
    "y_pred = model.predict(xline[:,None])\n",
    "\n",
    "plt.plot(x, y, '.');\n",
    "plt.plot(xline, y_pred, label='model');\n",
    "plt.hlines(y=y.mean(), xmin=0, xmax=10, label='mean')\n",
    "plt.legend()\n",
    "plt.xlabel('feature')\n",
    "plt.ylabel('target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we get a negative $R^2$?\n",
    "\n",
    "It is possible to get a negative $R^2$ when the model performs worse than the constant-mean predictor\n",
    "\n",
    "$R^2 = 1 -  \\frac{\\sum(y - \\hat{y})^2}{\\sum(y - \\bar{y})^2}$\n",
    "\n",
    "For a *bad* model, the numerator will be larger than the denominator, making the value negative.\n",
    "\n",
    "For linear regression it can happen when no intercept is fitted.\n",
    "\n",
    "See:\n",
    "\n",
    "https://stackoverflow.com/questions/30507245/negative-r2-on-training-data-for-linear-regression\n",
    "\n",
    "https://stats.stackexchange.com/questions/12900/when-is-r-squared-negative"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
